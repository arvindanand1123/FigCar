{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arvind/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import scipy.io\n",
    "import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 16, 128, 128,   3], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.truncated_normal([16,128,128,3])\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "sess.run(tf.shape(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   16, 49152], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=tf.reshape(a,[16,49152])\n",
    "sess.run(tf.shape(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_images(path):\n",
    "    \"\"\"Groups and renames images per car model in appropriate folders specified by path\"\"\"\n",
    "    path2 = path + 'Train/'\n",
    "    path3 = path + 'Validation/'\n",
    "    mat = scipy.io.loadmat(path + 'cars_annos.mat')\n",
    "    annotations = mat['annotations']\n",
    "    class_names = mat['class_names']\n",
    "    x = 0\n",
    "    for i in range((len(annotations[0]))):\n",
    "        car_name = class_names[0][annotations[0][i][5][0][0]-1][0]\n",
    "        car_name = car_name[:-5].replace(\" \", \"_\")\n",
    "        if car_name == 'Ram_C/V_Cargo_Van_Minivan':\n",
    "            car_name = 'Ram_C_MiniVan'\n",
    "        newpath = path2 + car_name\n",
    "        validation_path = path3 + car_name\n",
    "        if not os.path.exists(newpath):\n",
    "            os.makedirs(newpath)\n",
    "            os.makedirs(validation_path)\n",
    "            x = 0\n",
    "        src = path + annotations[0][i][0][0]\n",
    "        x = x + 1\n",
    "        try:\n",
    "            if(x == 1 or x == 2):\n",
    "                os.rename(src, validation_path + '/'+ car_name + str(x) + '.jpg')\n",
    "            else:\n",
    "                os.rename(src, newpath + '/'+ car_name + str(x-2) + '.jpg')\n",
    "        except:\n",
    "            pass\n",
    "group_images('/home/arvind/Documents/Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 189 total car categories.\n",
      "There are 16185 total car images.\n",
      "\n",
      "There are 15807 training car images.\n",
      "There are 378 validation car images.\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    car_files = np.array(data['filenames'])\n",
    "    car_targets = np_utils.to_categorical(np.array(data['target']), 189)\n",
    "    return car_files, car_targets\n",
    "\n",
    "train_files, train_targets = load_dataset('/home/arvind/Documents/Data/Train')\n",
    "valid_files, valid_targets = load_dataset('/home/arvind/Documents/Data/Validation')\n",
    "#test_files, test_targets = load_dataset('/home/arvind/Documents/Data/cars_test')\n",
    "\n",
    "car_names = [item[20:-1] for item in sorted(glob(\"/home/arvind/Documents/Data/Train/*/\"))]\n",
    "\n",
    "print('There are %d total car categories.' % len(car_names))\n",
    "print('There are %s total car images.\\n' % len(np.hstack([train_files, valid_files, test_files])))\n",
    "print('There are %d training car images.' % len(train_files))\n",
    "print('There are %d validation car images.' % len(valid_files))\n",
    "#print('There are %d test car images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from tqdm import tqdm\n",
    "def path_to_tensor(img_path):     \n",
    "    # loads RGB image as PIL.Image.Image type     \n",
    "    img = image.load_img(img_path, target_size=(224, 224))     \n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)     \n",
    "    x = image.img_to_array(img)     \n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor     \n",
    "    return np.expand_dims(x, axis=0)  \n",
    "def paths_to_tensor(img_paths):     \n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]     \n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15807/15807 [01:28<00:00, 179.08it/s]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-679472f080f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageFile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mImageFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOAD_TRUNCATED_IMAGES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaths_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mvalid_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaths_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#test_tensors = paths_to_tensor(test_files).astype('float32')/255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-adf05260f6f5>\u001b[0m in \u001b[0;36mpaths_to_tensor\u001b[0;34m(img_paths)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpaths_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlist_of_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpath_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "train_tensors = paths_to_tensor(train_files).astype('float64')/255\n",
    "valid_tensors = paths_to_tensor(valid_files).astype('float32')/255\n",
    "#test_tensors = paths_to_tensor(test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
